{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125310af-d1bf-4278-83e9-f8969aa57f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pytesseract import image_to_data, Output\n",
    "import matplotlib.pyplot as plt \n",
    "from more_itertools import windowed, flatten\n",
    "from itertools import groupby, chain\n",
    "from PIL import ImageDraw, Image, ImageFont\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from base64 import b64encode, b64decode\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shapely\n",
    "from shapely.geometry import box as shapely_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060bd4d-97cd-4a20-87af-a0ca12cba483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DATA = \"../input_data/\"\n",
    "OUTPUT_DATA = \"../out_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba00698-cdbf-4860-b3d8-24a03ef8e893",
   "metadata": {},
   "source": [
    "## Creación de data items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbc011-6c7e-4765-85b4-ec6587043620",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Levantado de la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cf7b1-b35c-46e3-bdea-eba1d69889c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    \"\"\"\n",
    "    img_path : str\n",
    "    Crea un data item por imagen\n",
    "    \"\"\"\n",
    "    if img_path.endswith(\".tif\"):            \n",
    "        imagen_cv = cv2.imread(img_path)\n",
    "        data_item = {}\n",
    "        data_item['file_path'] = img_path\n",
    "        data_item['img_bitmap'] = imagen_cv\n",
    "        data_item[\"image_shape\"] =  {\n",
    "            \"image_height\" : imagen_cv.shape[0], \n",
    "            \"image_width\" : imagen_cv.shape[1]\n",
    "            }\n",
    "        return data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d76af-6cda-4bd4-8271-9ec34d40da77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_item = load_image(\"../input_data/Ambito financiero 1987-12-04 Reacción en cadena por el caso Astiz.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a62e1e-bac1-4504-a84a-37b5012f7008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_item.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08c3c1-6d8c-475d-87c1-3eea07f30b8e",
   "metadata": {},
   "source": [
    "### Levantado de los json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fe918-23e0-43cb-b174-e81a75cdb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Caja(object):\n",
    "    \"\"\"Clase que define la estructura de datos del segmento etiquetado (bounding-box) como unidad.\"\"\"\n",
    "    def __init__(self, archivo, bounding_box, etiqueta, contenido):\n",
    "        self.file = archivo\n",
    "        self.x_1 = bounding_box['x']\n",
    "        self.y_1 = bounding_box['y']\n",
    "        self.x_2 = bounding_box['x'] + bounding_box['w'] \n",
    "        self.y_2 = bounding_box['y'] + bounding_box['h']\n",
    "        self.content = contenido\n",
    "        self.label = etiqueta\n",
    "        \n",
    "    def to_json(self):\n",
    "        return self.__dict__\n",
    "    \n",
    "    def to_pd_series(self):\n",
    "        return pd.Series(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cba4a-4a4c-436a-b77c-ca49a03be076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_segments_from_annotations(data_item):\n",
    "    \"\"\"\n",
    "    Función que extrae cada segmento de cada artículo existente en formato json en el \n",
    "    \"\"\"    \n",
    "    json_path = data_item['file_path'].replace('.tif','.json')\n",
    "    data_item['segments'] = []\n",
    "\n",
    "    if json_path.endswith(\".json\"):\n",
    "        with open(json_path, \"r\") as json_file:\n",
    "            datos = json.load(json_file)\n",
    "\n",
    "        print(datos['Diario'])\n",
    "\n",
    "        try:\n",
    "            caja = Caja(json_path.replace('.json', '.tif'), datos['Diario']['bounding_box'], 'Diario', datos['Diario']['texto'])\n",
    "            data_item['segments'].append(caja.to_json())\n",
    "            #print(f'Archivo: {caja.file} | Segmento: {segmento}  | Estado OK!')\n",
    "        except:\n",
    "            print(f'Archivo: {json_path} | Segmento: Diario  | Estado ERROR!')\n",
    "\n",
    "        try:\n",
    "            caja = Caja(json_path.replace('.json', '.tif'), datos['Fecha']['bounding_box'], 'Fecha', datos['Fecha']['texto'])\n",
    "            data_item['segments'].append(caja.to_json())\n",
    "            #print(f'Archivo: {caja.file} | Segmento: {segmento}  | Estado OK!')\n",
    "        except:\n",
    "            print(f'Archivo: {json_path} | Segmento: Fecha  | Estado ERROR!')\n",
    "\n",
    "        for nota in datos['Notas']:\n",
    "            for segmento in nota:\n",
    "                for detalle in nota[segmento]:\n",
    "                    try:\n",
    "                        caja = Caja(json_path.replace('.json', '.tif'), detalle['bounding_box'], segmento, detalle['texto'])\n",
    "                        data_item['segments'].append(caja.to_json())\n",
    "                        #print(f'Archivo: {caja.file} | Segmento: {segmento}  | Estado OK!')\n",
    "                    except:\n",
    "                        print(f'Archivo: {json_path} | Segmento: {segmento}  | Estado ERROR!')\n",
    "    \n",
    "    return data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adba8b1-e35b-4cac-8fd1-9fdc62f37c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_item = get_segments_from_annotations(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c95534-2c8f-4f02-91c2-76ef956148de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7b223-2364-467c-b091-f97aa35a4cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_item['segments'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fce03-9334-4c56-8c6d-55677a4b4cbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Obtener token boxes OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb1c1c-a23c-484b-b3cf-535622c06761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tess_configs = {\n",
    "    \"default\": \"--psm 11\",\n",
    "    \"psm3\": \"--psm 3\",\n",
    "    \"psm4\": \"--psm 4\",\n",
    "    \"psm5\": \"--psm 5\",\n",
    "    \"psm6\": \"--psm 6\",\n",
    "    \"psm12\": \"--psm 12\",\n",
    "}\n",
    "\n",
    "TESSERACT_LANG = \"spa\"\n",
    "TESSERACT_CONFIG = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287decb5-d860-461d-8410-057ed8887129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_token_boxes(image, tesseract_langs: str, tesseract_config: str ) -> list[dict]:\n",
    "    tess_config = tess_configs.get(tesseract_config, \"\")\n",
    "    data = image_to_data(\n",
    "        image,\n",
    "        lang=tesseract_langs,\n",
    "        config=tess_config,\n",
    "        output_type=Output.DICT,\n",
    "    )\n",
    "\n",
    "    data = zip(\n",
    "        data[\"text\"],\n",
    "        data[\"conf\"],\n",
    "        data[\"left\"],\n",
    "        data[\"top\"],\n",
    "        data[\"width\"],\n",
    "        data[\"height\"],\n",
    "    )\n",
    "\n",
    "    # box format =>  (x_left, y_top, x_right, y_bottom)\n",
    "    token_boxes = map(\n",
    "        lambda x: {\n",
    "            \"text\": x[0],\n",
    "            \"confidence\": float(x[1]) / 100,\n",
    "            \"top\": x[3],\n",
    "            \"left\": x[2],\n",
    "            \"box\": (x[2], x[3], x[2] + x[4], x[3] + x[5]),\n",
    "            \"box_area\": x[4] * x[5],\n",
    "            \"box_height\": x[5],\n",
    "            \"x_position\": x[2],\n",
    "            \"y_position\": x[3],\n",
    "        },\n",
    "        data,\n",
    "    )\n",
    "\n",
    "    token_boxes = [token for token in token_boxes if token[\"text\"]]\n",
    "\n",
    "    return token_boxes\n",
    "\n",
    "\n",
    "MIN_NEW_LINE_OVERLAP = 0.5\n",
    "\n",
    "def set_line_number(token_boxes: list[dict]) -> list[dict]:\n",
    "    token_boxes = sorted(\n",
    "        token_boxes, key=lambda x: ((x[\"box\"][3] + x[\"box\"][1]) / 2)\n",
    "    )\n",
    "\n",
    "    token_box_pairs = windowed(token_boxes, 2)\n",
    "    line = 1\n",
    "    token_boxes[0][\"n_line\"] = line\n",
    "    for prev_token_box, token_box in token_box_pairs:\n",
    "        prev_box = prev_token_box[\"box\"]\n",
    "        box = token_box[\"box\"]\n",
    "        prev_y = (prev_box[3] + prev_box[1]) / 2\n",
    "        y = (box[3] + box[1]) / 2\n",
    "        diff = abs(y - prev_y)\n",
    "        if (box[1] > prev_box[1]) and (box[3] < prev_box[3]):\n",
    "            token_box[\"n_line\"] = line\n",
    "            continue\n",
    "\n",
    "        height = token_box[\"box_height\"]\n",
    "        if diff >= height * MIN_NEW_LINE_OVERLAP:\n",
    "            line += 1\n",
    "\n",
    "        token_box[\"n_line\"] = line\n",
    "\n",
    "    return token_boxes\n",
    "\n",
    "\n",
    "def get_line_groups(token_boxes: list[dict]):\n",
    "    line_groups = groupby(token_boxes, key=lambda x: x[\"n_line\"])\n",
    "    line_groups = map(\n",
    "        lambda x: sorted(x[1], key=lambda x: x[\"box\"][0]), line_groups\n",
    "    )\n",
    "\n",
    "    return line_groups\n",
    "\n",
    "\n",
    "def set_token_box_ids(\n",
    "    token_boxes: list[dict[str]],\n",
    "    image_id: str,\n",
    ") -> list[dict[str]]:\n",
    "\n",
    "    line_groups = get_line_groups(token_boxes)\n",
    "    sorted_token_boxes = flatten(line_groups)\n",
    "    token_boxes_ = []\n",
    "    for idx, token_box in enumerate(sorted_token_boxes, start=1):\n",
    "        token_id = f\"{image_id}-{idx}\"\n",
    "        token_id = b64_encoder(token_id)\n",
    "        token_box_ = {\"id\": token_id, **token_box, \"n_token\": idx}\n",
    "        token_boxes_.append(token_box_)\n",
    "\n",
    "    return token_boxes_\n",
    "\n",
    "\n",
    "def b64_encoder(x: str) -> str:\n",
    "    encoded = b64encode(x.encode()).decode()\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def save_json(json_data, file_path: str):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(json.dumps(json_data, indent=4, ensure_ascii=False))\n",
    "        \n",
    "\n",
    "def cv2pil(cv_image: np.ndarray) -> Image:\n",
    "    image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(image)\n",
    "    return pil_image\n",
    "\n",
    "\n",
    "def apply_tesseract(\n",
    "    data_item,\n",
    "    tesseract_langs: str = \"spa\",\n",
    "    tesseract_config: str = \"default\",\n",
    "    output_path: str = \"\",\n",
    "):\n",
    "\n",
    "    data_item = deepcopy(data_item)\n",
    "    image_path = data_item[\"file_path\"]\n",
    "    img = data_item[\"img_bitmap\"]\n",
    "    image = cv2pil(img)\n",
    "\n",
    "    image_path = data_item[\"file_path\"]\n",
    "    filename = os.path.basename(image_path)\n",
    "    image_id = f\"{filename}\"\n",
    "\n",
    "    token_boxes = get_token_boxes(image, tesseract_langs, tesseract_config)\n",
    "    token_boxes = set_line_number(token_boxes)\n",
    "    token_boxes = set_token_box_ids(\n",
    "        token_boxes,\n",
    "        image_id,\n",
    "    )\n",
    "\n",
    "    if not token_boxes:\n",
    "        logger.warning(f\"WARNING no boxes for image => {image_path}\")\n",
    "        return\n",
    "\n",
    "    data_item[\"token_boxes\"] = token_boxes\n",
    "\n",
    "    if output_path:\n",
    "        path = Path(output_path)\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        file_hash = b64_encoder(data_item[\"file_path\"])\n",
    "        save_json(token_boxes, f\"{output_path}/{file_hash}.json\")\n",
    "\n",
    "    return data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d8bef-9277-456d-8524-17ad368bb4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_item = apply_tesseract(data_item, output_path=OUTPUT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f5fbb-d73b-4b8d-be78-695d1b10e80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a561ec4-5faf-4d31-9c28-4e1c8945df97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
